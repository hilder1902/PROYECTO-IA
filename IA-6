""" YA CIERRA CON CTRL + C, SE LE APLICO AJUSTE AUTOMATICO DE LOS HIPERAMETROS Y EPOCAS TMABIEN SE LE MEJORO: ‚úÖ Escalado corregido: Ahora scaler solo se ajusta una vez y se reutiliza.
‚úÖ Regularizaci√≥n a√±adida: Dropout en las capas LSTM para reducir sobreajuste.
‚úÖ Cambio de funci√≥n de p√©rdida: Huber Loss para mayor estabilidad.
‚úÖ M√©trica mejorada: Se usa R¬≤ en lugar de una m√©trica arbitraria.
‚úÖ TIENE UN PRECISION DEL 80% PARA QUE SEA MAS ALCANZABLE """




".\mi_entorno_1\Scripts\Activate"

"numero de cuenta" "197115903"

"servidor" "Exness-MT5Trial11"

".\mi_entorno_1\Scripts\Activate"

import MetaTrader5 as mt5 
import logging
import time

import tensorflow as tf
from tensorflow import keras

import scipy as sp
import pandas as pd
import numpy as np
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import accuracy_score, mean_absolute_error
from sklearn.preprocessing import MinMaxScaler

# Definir capas de Keras
Input = tf.keras.layers.Input
LSTM = tf.keras.layers.LSTM
Dense = tf.keras.layers.Dense
Attention = tf.keras.layers.Attention
Dropout = tf.keras.layers.Dropout

# Importar modelos y optimizadores desde tf.keras
Model = tf.keras.models.Model
Sequential = tf.keras.models.Sequential
Adam = tf.keras.optimizers.Adam
EarlyStopping = tf.keras.callbacks.EarlyStopping


import tensorflow as tf
import numpy as np
import pandas as pd
import MetaTrader5 as mt5
import pickle
import logging
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))










import pickle
import logging
import numpy as np
import pandas as pd
import MetaTrader5 as mt5
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score

# ‚ö° Buffer para almacenar errores pasados
error_memoria = []

scaler = StandardScaler()

def cargar_modelo():
    """Carga el modelo desde un archivo o crea uno nuevo si no existe."""
    try:
        with open("modelo_entrenado.pkl", "rb") as f:
            modelo = pickle.load(f)
        logging.info("Modelo cargado correctamente.")
    except (FileNotFoundError, EOFError):
        logging.info("No se encontr√≥ un modelo entrenado. Creando uno nuevo...")
        modelo = crear_nuevo_modelo()
    return modelo

def crear_nuevo_modelo(units_1=64, units_2=32, dense_units=16, dropout_rate=0.2):
    """Crea un nuevo modelo con hiperpar√°metros ajustables y regularizaci√≥n."""
    modelo = tf.keras.Sequential([
        tf.keras.layers.LSTM(units_1, return_sequences=True, input_shape=(50, 1)),
        tf.keras.layers.Dropout(dropout_rate),
        tf.keras.layers.LSTM(units_2),
        tf.keras.layers.Dropout(dropout_rate),
        tf.keras.layers.Dense(dense_units, activation="relu"),
        tf.keras.layers.Dense(1)
    ])
    modelo.compile(optimizer="adam", loss=tf.keras.losses.Huber(delta=1.0), metrics=["mae"])
    return modelo

def obtener_datos_mt5(simbolo, timeframe, n_candles):
    """Obtiene los datos hist√≥ricos desde MetaTrader 5."""
    rates = mt5.copy_rates_from_pos(simbolo, timeframe, 0, n_candles)
    if rates is None or len(rates) < n_candles:
        logging.warning(f"No se pudieron obtener suficientes datos para {simbolo}.")
        return None
    df = pd.DataFrame(rates)[['close']]
    
    if not hasattr(obtener_datos_mt5, "scaler_fitted"):
        scaler.fit(df[['close']])
        obtener_datos_mt5.scaler_fitted = True  # Evita reajustar en cada llamada
    
    df['close'] = scaler.transform(df[['close']])
    return df

def preparar_datos(df):
    """Prepara los datos para el entrenamiento del modelo."""
    X, y = [], []
    for i in range(len(df) - 50):
        X.append(df.iloc[i:i+50].values)
        y.append(df.iloc[i+50].values)
    return np.array(X), np.array(y)

def entrenar_modelo(modelo, X_train, y_train, X_test, y_test, precision_objetivo=0.86):
    """Entrena el modelo con auto-ajuste de hiperpar√°metros basado en errores pasados."""
    global error_memoria
    epochs = 10
    intentos = 0
    mejor_precision = 0
    mejor_modelo = None

    while intentos < 5:
        modelo.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1)
        precision = evaluar_modelo(modelo, X_test, y_test)
        logging.info(f"Intento {intentos+1} - Precisi√≥n: {precision:.4f} - √âpocas: {epochs}")

        if precision > mejor_precision:
            mejor_precision = precision
            mejor_modelo = modelo
            guardar_modelo(mejor_modelo)

        # üî• Aprendizaje de errores: si el error es alto, reentrenar con ajustes din√°micos
        if error_memoria and np.mean(error_memoria[-10:]) > 0.01:
            logging.info("‚ö° Detectado alto error en predicciones recientes. Ajustando hiperpar√°metros...")
            modelo = crear_nuevo_modelo(units_1=128, units_2=64, dense_units=32)

        if precision >= precision_objetivo:
            logging.info("‚úÖ Precisi√≥n objetivo alcanzada. Entrenamiento detenido.")
            break
        else:
            epochs += 5
        intentos += 1

    return mejor_modelo if mejor_modelo else modelo

def evaluar_modelo(modelo, X_test, y_test):
    """Eval√∫a la precisi√≥n del modelo usando R¬≤ en lugar de MAE."""
    y_pred = modelo.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    return r2

def guardar_modelo(modelo):
    """Guarda el modelo entrenado en un archivo."""
    with open("modelo_entrenado.pkl", "wb") as f:
        pickle.dump(modelo, f)
    logging.info("üíæ Modelo guardado correctamente.")

def hacer_prediccion(modelo, df):
    """Realiza una predicci√≥n basada en los √∫ltimos 50 datos."""
    recent_data = df[-50:].values.reshape(1, 50, -1)
    prediccion = modelo.predict(recent_data)[0][0]
    return scaler.inverse_transform([[prediccion]])[0][0]

def evaluar_prediccion(prediccion, actual):
    """Calcula el error de predicci√≥n y lo almacena para ajustar el modelo en el futuro."""
    global error_memoria
    error = abs(prediccion - actual)
    error_memoria.append(error)

    # üî• Si el error es alto, reentrenamos parcialmente el modelo con los √∫ltimos datos
    if error > 0.01:
        logging.warning(f"‚ö†Ô∏è Alta diferencia en predicci√≥n: {error:.4f}. Reentrenando en tiempo real...")
        modelo = cargar_modelo()
        df = obtener_datos_mt5("EURUSDm", mt5.TIMEFRAME_M1, 1000)
        if df is not None:
            X, y = preparar_datos(df)
            modelo.fit(X, y, epochs=3, batch_size=16, verbose=0)
            guardar_modelo(modelo)

    return error











import logging
import time
import pickle
import MetaTrader5 as mt5
import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler

def main():
    # Configurar logging
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    # Inicializar MetaTrader 5
    if not mt5.initialize():
        logging.error("Error al inicializar MetaTrader 5.")
        exit()

    # Inicializar el escalador
    scaler = MinMaxScaler(feature_range=(0, 1))

    # Cargar o crear el modelo
    try:
        with open("modelo_entrenado.pkl", "rb") as f:
            modelo = pickle.load(f)
        logging.info("Modelo cargado correctamente.")
    except (FileNotFoundError, EOFError):
        logging.info("No se encontr√≥ un modelo entrenado. Creando uno nuevo...")
        modelo = tf.keras.Sequential([
            tf.keras.layers.LSTM(64, return_sequences=True, input_shape=(50, 1)),
            tf.keras.layers.LSTM(32),
            tf.keras.layers.Dense(16, activation="relu"),
            tf.keras.layers.Dense(1)
        ])
        modelo.compile(optimizer="adam", loss="mse", metrics=["mae"])

    pares_divisas = ["EURUSDm", "GBPUSDm", "USDJPYm", "AUDUSDm", "USDCADm"]

    for simbolo in pares_divisas:
        while True:
            logging.info(f"Entrenando para {simbolo}...")
            rates = mt5.copy_rates_from_pos(simbolo, mt5.TIMEFRAME_M1, 0, 500)
            if rates is None or len(rates) < 500:
                logging.warning(f"No se pudieron obtener suficientes datos para {simbolo}.")
                break

            df = pd.DataFrame(rates)[['close']]
            df['close'] = scaler.fit_transform(df[['close']])

            X, y = [], []
            for i in range(len(df) - 50):
                X.append(df.iloc[i:i+50].values)
                y.append(df.iloc[i+50].values)
            X, y = np.array(X), np.array(y)

            if len(X) == 0:
                logging.warning(f"Datos insuficientes para {simbolo}. Pasando al siguiente...")
                break

            split = int(len(X) * 0.8)
            X_train, X_test, y_train, y_test = X[:split], X[split:], y[:split], y[split:]

            epochs, intentos, mejor_precision = 10, 0, 0
            mejor_modelo = None

            while intentos < 5:
                modelo.fit(X_train, y_train, epochs=epochs, batch_size=32, verbose=1)
                mae = modelo.evaluate(X_test, y_test, verbose=0)[1]
                precision = max(1 - mae / np.mean(y_test), 0)
                logging.info(f"Intento {intentos+1} - Precisi√≥n: {precision:.4f} - √âpocas: {epochs}")

                if precision > mejor_precision:
                    mejor_precision = precision
                    mejor_modelo = modelo
                    with open("modelo_entrenado.pkl", "wb") as f:
                        pickle.dump(mejor_modelo, f)
                    logging.info("Modelo guardado correctamente.")

                if precision >= 0.80:  # Se ajusta el umbral de precisi√≥n del 86% al 80%
                    logging.info("Precisi√≥n objetivo alcanzada. Entrenamiento detenido.")
                    break
                else:
                    epochs += 5
                    if intentos % 2 == 0:
                        logging.info("Reajustando hiperpar√°metros...")
                        modelo = tf.keras.Sequential([
                            tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(50, 1)),
                            tf.keras.layers.LSTM(64),
                            tf.keras.layers.Dense(32, activation="relu"),
                            tf.keras.layers.Dense(1)
                        ])
                        modelo.compile(optimizer="adam", loss="mse", metrics=["mae"])

                intentos += 1

            if precision >= 0.80:
                break

            logging.info(f"Reentrenando {simbolo} hasta alcanzar el 80%...")
            time.sleep(10)

    logging.info("Modelo guardado despu√©s de entrenar todos los s√≠mbolos.")

    while True:
        for simbolo in pares_divisas:
            logging.info(f"Iniciando predicci√≥n para {simbolo}...")
            rates = mt5.copy_rates_from_pos(simbolo, mt5.TIMEFRAME_M1, 0, 50)
            if rates is None:
                continue

            df = pd.DataFrame(rates)[['close']]
            df['close'] = scaler.transform(df[['close']])

            recent_data = df[-50:].values.reshape(1, 50, -1)
            prediccion = modelo.predict(recent_data)[0][0]
            prediccion_real = scaler.inverse_transform([[prediccion]])[0][0]

            current_price = df.iloc[-1]['close']
            logging.info(f"Predicci√≥n en 5s para {simbolo}: {prediccion_real:.6f}, Precio actual: {current_price:.6f}")

            if prediccion_real > current_price:
                logging.info(f"Se√±al de COMPRA para {simbolo}")
            elif prediccion_real < current_price:
                logging.info(f"Se√±al de VENTA para {simbolo}")
            else:
                logging.info(f"No hay se√±al clara para {simbolo}")

            time.sleep(5)
            df_actual = mt5.copy_rates_from_pos(simbolo, mt5.TIMEFRAME_M1, 0, 1)
            if df_actual is None:
                continue

            actual_price = pd.DataFrame(df_actual)['close'].iloc[-1]
            error = abs(prediccion_real - actual_price)
            logging.info(f"Precio real despu√©s de 5s para {simbolo}: {actual_price:.6f}")
            logging.info(f"Error de predicci√≥n: {error:.6f}")

if __name__ == "__main__":
    main()
