""" YA CIERRA CON CTRL + C, SE LE APLICO AJUSTE AUTOMATICO DE LOS HIPERAMETROS Y EPOCAS TMABIEN SE LE MEJORO.
‚úÖ Escalado corregido: Ahora scaler solo se ajusta una vez y se reutiliza.
‚úÖ Regularizaci√≥n a√±adida: Dropout en las capas LSTM para reducir sobreajuste.
‚úÖ Cambio de funci√≥n de p√©rdida: Huber Loss para mayor estabilidad.
‚úÖ M√©trica mejorada: Se usa R¬≤ en lugar de una m√©trica arbitraria.
‚úÖ CAMBIE EL ENFOQUE DE PREDICCION POR UNO QUE PREDICE SI EL MERCADO EN 5 SEGUNDOS SUBE O BAJA, PARECE QUE FUNCIONA, ARREGLARE UN POCO EL CODIGO.
‚úÖ YA LA IA SE ENTRENA Y PREDICE DESPUES DE ENTRENAR LAS PREDCCIONES LAS HACE BIEN PERO AUN LE FALTAN, Y SOLO DA SE√ëALES DE COMPRA TOCA CONSTATAR SI TAMBIEN DA SE√ëALES DE VENTA.
‚úÖ YA CORREGI LOS MENSAJES DE VERIFICACION DE LA PREDICCION, TOCA REGTIFICAR EN PROXIMAS ACTUALIZACIONES  SI LAS PREDICCIONES SON CORRECTAS MEDIANTE EL PRECIO INCIAL Y FINAL. 
‚úÖ YA CORREGI LA SALIDA DEL PRECIO DESPUES DE LOS 5 SEGUUNDOS, EL ERROR QUE HAY AHORA ES QUE LOS PRECIOS DE INCIO Y FINAL SON LOS MISMOS Y NO VARIAN.
‚úÖ EN LA FUNCION DE PREDICCION Y EN LA DE EVALUAR LE A√ëADI LA LOGICA INTERNA DE OBTENER EL PRECIO DIRECTAMENTE DE MT5 , ES DECIR LA OBTENCIO DEL PRECIO DE MT5 NO ES EXTERNA SE HACE DENTRO DE LA FUNCION.
‚úÖ LE AGREGUE UNA MEJRO VERIFICACION A EVALUAR LA PREDICCION.
‚úÖ MEJORE LA LEJIVILIDAD DEL PRECIO DA EL PRECIO ANTES Y DESPUES CORRECTAMENTE PERO LA EVALUCION LA HACE MAL.
‚úÖ YA EVALUA CORRECTAMENTE LAS OPERACIONES, EL ERROR AHORA ES QUE GURARDA LAS PREDICCIONES EN EL ACRICHO TXT INCORRECTO.
‚úÖ YA LOS ARCHIVOS SE GUARDAN CORRECTAMENTE Y LOS BLOQUES ESTAN BIEN SEPARADOS.
‚úÖ OPERA EN PARALELO MULTIPLES SIMBOLOS, YA VERIFIQUE, PERO AUN NO HACE LAS PREDICCIONES TODAS AL MISMO TIEMPO, LE AGREGUE DIFERENCIACION DE CENTAVOS, DOLAR Y DOLARES CON LA DIFRENCIA.
‚úÖ YA PREDICE TODO, YA SALE TODO EN ORDEN Y CON TODOS LOS SIMBOLOS PERO NECECITO QUE SEAN LOS MISMOS MENSAJES, TOCA CAMBIAR ALGUNAS COSAS.
‚úÖ EL MODELO LE DA LA MISMA IMPORTANCIA A TODOS LOS PARES, YA SE GUARDAN LAS PREDICCIONES EN SUS CITIOS CORRESPONDIENTES.
‚úÖ ESTA TODO MAS ORGANIZADO PERO SOLO PREDICE QUE SUBE NUCA DICE QUE BAJA.
‚úÖ SE ELIMINO EL SESGO DE PREDICCION, YA NO SE ESTANCA UNICAMENTE EN UNA DIRECCION, LA CALIDAD DE LAS PREDICCIONES MEJORARON SIGNIFICATIVAMENTE.
IA -19 """






".\mi_entorno_1\Scripts\Activate"

"numero de cuenta" "197115903"

"servidor" "Exness-MT5Trial11"

".\mi_entorno_1\Scripts\Activate"

" promt:  actua como un programador se√±or experto en IA y trading algoritmico"

import MetaTrader5 as mt5 
import logging
import time

import tensorflow as tf
from tensorflow import keras

import scipy as sp
import pandas as pd
import numpy as np
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'

from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import accuracy_score, mean_absolute_error
from sklearn.preprocessing import MinMaxScaler

# Definir capas de Keras
Input = tf.keras.layers.Input
LSTM = tf.keras.layers.LSTM
Dense = tf.keras.layers.Dense
Attention = tf.keras.layers.Attention
Dropout = tf.keras.layers.Dropout

# Importar modelos y optimizadores desde tf.keras
Model = tf.keras.models.Model
Sequential = tf.keras.models.Sequential
Adam = tf.keras.optimizers.Adam
EarlyStopping = tf.keras.callbacks.EarlyStopping


import tensorflow as tf
import numpy as np
import pandas as pd
import MetaTrader5 as mt5
import pickle
import logging
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler(feature_range=(0, 1))
import time
import logging
import numpy as np
import MetaTrader5 as mt5
import pickle
import logging
import numpy as np
import pandas as pd
import MetaTrader5 as mt5
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score
import MetaTrader5 as mt5
import pandas as pd
import numpy as np
import logging
from sklearn.preprocessing import MinMaxScaler
import re

from datetime import datetime

import time

from datetime import datetime

import locale
from datetime import datetime

import logging
import time
import pandas as pd
import MetaTrader5 as mt5
from concurrent.futures import ThreadPoolExecutor
from sklearn.preprocessing import MinMaxScaler

import MetaTrader5 as mt5
import logging
import time
import pandas as pd
from concurrent.futures import ThreadPoolExecutor
from sklearn.preprocessing import MinMaxScaler

import datetime  # Agregar esta l√≠nea arriba si a√∫n no est√°
import time
import logging
from concurrent.futures import ThreadPoolExecutor
import MetaTrader5 as mt5
import tensorflow as tf














# ‚ö° Buffer para almacenar errores pasados
error_memoria = []

scaler = StandardScaler()

def cargar_modelo():
    """Carga el modelo desde un archivo o crea uno nuevo si no existe."""
    try:
        with open("modelo_entrenado.pkl", "rb") as f:
            modelo = pickle.load(f)
        logging.info("Modelo cargado correctamente.")
    except (FileNotFoundError, EOFError):
        logging.info("No se encontr√≥ un modelo entrenado. Creando uno nuevo...")
        modelo = crear_nuevo_modelo()
    return modelo



def crear_nuevo_modelo(units_1=64, units_2=32, dense_units=16, dropout_rate=0.2):
    """Crea un modelo optimizado con mayor estabilidad, mejor aprendizaje y generalizaci√≥n."""
    modelo = tf.keras.Sequential([
        tf.keras.layers.LSTM(units_1, return_sequences=True, input_shape=(50, 1),
                             kernel_initializer="glorot_uniform", recurrent_initializer="orthogonal",
                             bias_initializer="zeros", recurrent_regularizer=tf.keras.regularizers.l2(1e-4),
                             return_state=False, stateful=False, dropout=0.1, recurrent_dropout=0.1),
        tf.keras.layers.LayerNormalization(),  # Alternativa a BatchNormalization, mejor en secuencias largas
        tf.keras.layers.Dropout(dropout_rate),
        
        tf.keras.layers.LSTM(units_2, kernel_initializer="glorot_uniform",
                             recurrent_initializer="orthogonal", bias_initializer="zeros",
                             recurrent_regularizer=tf.keras.regularizers.l2(1e-4),
                             return_state=False, stateful=False, dropout=0.1, recurrent_dropout=0.1),
        tf.keras.layers.LayerNormalization(),
        tf.keras.layers.Dropout(dropout_rate),
        
        tf.keras.layers.Dense(dense_units, activation="relu",
                              kernel_initializer="he_normal", bias_initializer="zeros",
                              kernel_regularizer=tf.keras.regularizers.l2(1e-4)),
        
        tf.keras.layers.Dense(1, kernel_initializer="glorot_uniform", bias_initializer="zeros")
    ])
    
    modelo.compile(optimizer=tf.keras.optimizers.AdamW(learning_rate=0.0008, weight_decay=1e-4, epsilon=1e-7, amsgrad=True),
                   loss=tf.keras.losses.Huber(delta=1.0),
                   metrics=[tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.RootMeanSquaredError()])
    
    return modelo



scaler = MinMaxScaler(feature_range=(0, 1))  # Escalador global para normalizaci√≥n

def obtener_datos_mt5(simbolo, timeframe, n_candles):
    """Obtiene los datos hist√≥ricos desde MetaTrader 5 con mejoras en robustez y eficiencia."""
    
    rates = mt5.copy_rates_from_pos(simbolo, timeframe, 0, n_candles)
    
    if rates is None or len(rates) < n_candles:
        logging.warning(f"No se pudieron obtener suficientes datos para {simbolo}.")
        return None
    
    df = pd.DataFrame(rates, columns=['close'])  # Asegura que solo se tome 'close'
    
    if df.isnull().values.any() or df.empty:  # Previene errores por datos nulos o vac√≠os
        logging.error(f"Datos recibidos contienen NaN o est√°n vac√≠os para {simbolo}.")
        return None

    # Evita recalibrar el scaler en cada llamada
    if not hasattr(obtener_datos_mt5, "scaler_fitted"):
        scaler.fit(df[['close']])
        obtener_datos_mt5.scaler_fitted = True

    df['close'] = scaler.transform(df[['close']]).astype(np.float32)  # Optimizaci√≥n de tipo de dato

    return df





def preparar_datos(df):
    """Prepara los datos para el entrenamiento del modelo con optimizaci√≥n en rendimiento y seguridad."""
    
    if df is None or df.empty:
        raise ValueError("El DataFrame de entrada est√° vac√≠o o es None.")
    
    df_values = df.values.astype(np.float32)  # Optimizaci√≥n de tipo de dato
    X, y = [], []
    secuencia = 50
    
    for i in range(len(df_values) - secuencia):
        X.append(df_values[i:i + secuencia])
        y.append(df_values[i + secuencia])
    
    return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)




import keras
import numpy as np
import logging

EarlyStopping = keras.callbacks.EarlyStopping  
ReduceLROnPlateau = keras.callbacks.ReduceLROnPlateau  

def entrenar_modelo(modelo, X_train, y_train, X_test, y_test, precision_objetivo=0.86):
    """Entrena el modelo en un solo intento con optimizaci√≥n extrema para garantizar m√≠nimo 86% de precisi√≥n."""

    global error_memoria
    epochs = 20  # üî• Se aumenta a 20 para garantizar convergencia sin necesidad de reintentos
    mejor_precision = 0.0
    mejor_modelo = None

    # Callbacks para optimizaci√≥n avanzada
    early_stopping = EarlyStopping(monitor="val_loss", patience=4, restore_best_weights=True, min_delta=1e-4)
    lr_scheduler = ReduceLROnPlateau(monitor="val_loss", factor=0.5, patience=2, min_lr=1e-6)

    # üî• ENTRENAMIENTO √öNICO CON HIPEROPTIMIZACI√ìN
    historial = modelo.fit(
        X_train, y_train,
        epochs=epochs,
        batch_size=64,  # Ajuste fino para estabilidad sin perder velocidad
        verbose=1,
        validation_data=(X_test, y_test),
        callbacks=[early_stopping, lr_scheduler]
    )

    precision = evaluar_modelo(modelo, X_test, y_test)
    logging.info(f"üìä Entrenamiento √∫nico - Precisi√≥n: {precision:.4f} - √âpocas: {epochs}")

    # Guardar el mejor modelo
    if precision > mejor_precision:
        mejor_precision = precision
        mejor_modelo = modelo
        guardar_modelo(mejor_modelo)

    # üî• Aprendizaje din√°mico de errores con reajuste extremo
    if error_memoria and len(error_memoria) >= 10 and np.mean(error_memoria[-10:]) > 0.01:
        logging.warning("‚ö° Error elevado en predicciones recientes. Reajustando hiperpar√°metros din√°micamente...")
        modelo = crear_nuevo_modelo(units_1=256, units_2=128, dense_units=64, dropout_rate=0.3)  # üî• Optimizamos unidades
        mejor_precision = 0  # Reset para evitar falsos positivos

    # üöÄ Condici√≥n de √©xito absoluto
    if precision >= precision_objetivo:
        logging.info("‚úÖ Precisi√≥n objetivo alcanzada en un solo intento. Entrenamiento finalizado.")
    else:
        logging.warning(f"‚ö†Ô∏è Precisi√≥n insuficiente ({precision:.4f}). Ajusta datos o hiperpar√°metros manualmente.")

    return mejor_modelo if mejor_modelo else modelo



def evaluar_modelo(modelo, X_test, y_test):
    """Eval√∫a la precisi√≥n del modelo usando R¬≤ en lugar de MAE."""
    y_pred = modelo.predict(X_test)
    r2 = r2_score(y_test, y_pred)
    return r2

def guardar_modelo(modelo):
    """Guarda el modelo entrenado en un archivo."""
    with open("modelo_entrenado.pkl", "wb") as f:
        pickle.dump(modelo, f)
    logging.info("üíæ Modelo guardado correctamente.")














import MetaTrader5 as mt5
import numpy as np
import datetime
import time
import locale
import logging
from concurrent.futures import ThreadPoolExecutor

def predecir_todos_los_simbolos(modelo, dfs, simbolos, scaler, tp=0.0001):
    """
    Realiza predicciones en paralelo para todos los s√≠mbolos utilizando el m√©todo de predicci√≥n refinado.
    """
    resultados_globales = {}

    def procesar_simbolo(simbolo):
        try:
            if simbolo not in dfs or dfs[simbolo].empty:
                logging.warning(f"‚ö†Ô∏è No hay datos suficientes para {simbolo}.")
                return simbolo, None, None, None

            # Obtener el precio actual
            precio_actual = None
            tick_info = mt5.symbol_info_tick(simbolo)

            if tick_info and isinstance(tick_info.bid, (int, float)):
                precio_actual = float(tick_info.bid)
                logging.info(f"‚úî Precio inicial obtenido de MT5 ({simbolo}): {precio_actual:,.5f}")
            else:
                logging.error(f"‚ùå No se pudo obtener un precio inicial v√°lido para {simbolo}.")
                return simbolo, None, None, None  

            # Preparar los datos de entrada
            recent_data = dfs[simbolo][-50:].values.reshape(1, 50, -1)
            prediccion_simbolo = modelo.predict(recent_data)[0][0]

            # Aplicar inverse transform si el scaler est√° configurado
            if hasattr(scaler, "min_") and hasattr(scaler, "scale_"):
                prediccion_real = scaler.inverse_transform(np.array([[prediccion_simbolo]]))[0][0]
            else:
                logging.error(f"‚ö†Ô∏è El scaler no ha sido ajustado antes de hacer inverse_transform en {simbolo}.")
                prediccion_real = prediccion_simbolo  

            # Determinar direcci√≥n y precio objetivo
            if prediccion_real > precio_actual + tp:
                direccion = "üìà SUBE"
                precio_objetivo = precio_actual + tp
            elif prediccion_real < precio_actual - tp:
                direccion = "üìâ BAJA"
                precio_objetivo = precio_actual - tp
            else:
                direccion = "üü∞ SIN CAMBIO"
                precio_objetivo = precio_actual  

            return simbolo, precio_actual, direccion, precio_objetivo

        except Exception as e:
            logging.warning(f"‚ö†Ô∏è Error al procesar {simbolo}: {str(e)}")
            return simbolo, None, None, None

    # Ejecutar en paralelo
    with ThreadPoolExecutor(max_workers=len(simbolos)) as executor:
        futuros = {executor.submit(procesar_simbolo, simbolo): simbolo for simbolo in simbolos}

        for futuro in futuros:
            simbolo, precio_actual, direccion, precio_objetivo = futuro.result()
            if precio_actual is not None:
                logging.info(f"{simbolo} - Precio actual: {precio_actual:,.5f}, Predicci√≥n: {direccion} (Objetivo TP: {precio_objetivo:,.5f})")
                resultados_globales[simbolo] = (precio_actual, direccion, precio_objetivo)

    if not resultados_globales:
        logging.warning("‚ùå No se realizaron predicciones debido a falta de datos.")
        return

    logging.info("\n‚è≥ Esperando 5 segundos para evaluar el resultado...\n")
    time.sleep(5)

    # Evaluar predicciones despu√©s de 5 segundos
    resultados_futuros = {}
    for simbolo in resultados_globales.keys():
        tick_final = mt5.symbol_info_tick(simbolo)
        if tick_final:
            precio_final = tick_final.ask if resultados_globales[simbolo][1] == "üìà SUBE" else tick_final.bid
            logging.info(f"‚úî Precio despu√©s de 5 segundos ({simbolo}): {precio_final:,.5f}")
            resultados_futuros[simbolo] = precio_final

    logging.info("\nüîç Comparativa de precios:")
    for simbolo in resultados_globales:
        if simbolo in resultados_futuros:
            precio_inicial = resultados_globales[simbolo][0]
            precio_final = resultados_futuros[simbolo]
            diferencia = abs(precio_final - precio_inicial)

            # Clasificaci√≥n de la diferencia
            if diferencia >= 2:
                unidad = "d√≥lares"
            elif diferencia >= 1:
                unidad = "d√≥lar"
            else:
                unidad = "centavos de d√≥lar"

            logging.info(f"   - Diferencia de: {diferencia:,.5f} {unidad} para ({simbolo})")

    logging.info("\n")
    for simbolo in resultados_globales:
        if simbolo in resultados_futuros:
            precio_inicial, direccion, objetivo_tp = resultados_globales[simbolo]
            precio_final = resultados_futuros[simbolo]

            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            if (direccion == "üìà SUBE" and precio_final >= objetivo_tp) or (direccion == "üìâ BAJA" and precio_final <= objetivo_tp):
                logging.info(f"‚úÖ  Predicci√≥n correcta: El precio {direccion} y alcanz√≥ el Take Profit (TP) con precio de {precio_final:,.5f}. ({simbolo})")

                with open("correctas.txt", "a", encoding="utf-8") as file:
                    file.write(f"{timestamp} - {simbolo} - {direccion} (CORRECTA) - Precio inicial: {precio_inicial:,.5f}, Precio final: {precio_final:,.5f}\n")

                logging.info(f"üìÇ Predicci√≥n guardada en CORRECTAS ‚úÖ: {simbolo}  {direccion}")

            else:
                logging.warning(f"‚ùå Predicci√≥n incorrecta: NO {direccion}. ({simbolo})")

                with open("incorrectas.txt", "a", encoding="utf-8") as file:
                    file.write(f"{timestamp} - {simbolo} - {direccion} (INCORRECTA) - Precio inicial: {precio_inicial:,.5f}, Precio final: {precio_final:,.5f}\n")

                logging.warning(f"üìÇ Predicci√≥n guardada en INCORRECTAS ‚ùå: {simbolo}  {direccion}")

            logging.info(f"   Precio inicial: {precio_inicial:,.5f}, Precio final: {precio_final:,.5f}\n")
            return resultados_globales, resultados_futuros

# Configurar el formato num√©rico americano
locale.setlocale(locale.LC_NUMERIC, "en_US.UTF-8")

def formatear_precio(precio):
    return locale.format_string("%.6f", precio, grouping=True).replace(",", "X").replace(".", ",").replace("X", ".")

def buscar_por_fecha(archivo, fecha):
    with open(archivo, "r") as f:
        lineas = f.readlines()
    
    resultados = [linea for linea in lineas if fecha in linea]
    return resultados










import MetaTrader5 as mt5
import pandas as pd
import numpy as np
import tensorflow as tf
import datetime
import logging
import os
import time
from collections import deque
from sklearn.preprocessing import MinMaxScaler

# üîπ Variables Globales
total_predicciones = 0
aciertos_totales = 0
mejor_precision = 0
memoria_errores = deque(maxlen=50)  # Buffer de memoria para errores recientes
epsilon = 0.1  # Exploraci√≥n inicial

import tensorflow as tf
import datetime
import os
import logging
from collections import deque
import numpy as np

# Inicializaci√≥n de memoria de errores
memoria_errores = deque(maxlen=100)  # Para almacenar los √∫ltimos 100 errores
epsilon = 0.1  # Tasa inicial de exploraci√≥n-explotaci√≥n

import tensorflow as tf
import datetime
import os
import logging
from collections import deque
import numpy as np

# Inicializaci√≥n de memoria de errores
memoria_errores = deque(maxlen=100)
epsilon = 0.1

import tensorflow as tf
import datetime
import os
import logging
from collections import deque
import numpy as np

# Inicializaci√≥n de memoria de errores
memoria_errores = deque(maxlen=100)
epsilon = 0.1

def evaluar_predicciones(resultados_globales, resultados_futuros, modelo, X_train, y_train, ruta_guardado):
    """Eval√∫a predicciones y ajusta el modelo en tiempo real con refuerzo inmediato."""
    global total_predicciones, aciertos_totales, mejor_precision, memoria_errores, epsilon

    mse_loss = tf.keras.losses.MeanSquaredError()

    # ‚úÖ Asegurar que X_train e y_train sean numpy arrays
    if X_train is None or y_train is None:
        raise ValueError("üö® Error: X_train o y_train son None. Revisa los datos de entrada.")

    X_train = np.array(X_train, dtype=np.float32)
    y_train = np.array(y_train, dtype=np.float32)

    print(f"‚úÖ X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")

    for simbolo in resultados_globales:
        if simbolo in resultados_futuros and total_predicciones < 5000:
            precio_inicial, direccion, objetivo_tp = resultados_globales[simbolo]
            precio_final = resultados_futuros[simbolo]
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            # üìå Evaluaci√≥n de la predicci√≥n y asignaci√≥n de recompensa
            if (direccion == "üìà SUBE" and precio_final >= objetivo_tp) or (direccion == "üìâ BAJA" and precio_final <= objetivo_tp):
                recompensa = 1.5 if aciertos_totales % 5 == 4 else 1
                aciertos_totales += 1
                logging.info(f"‚úÖ  Predicci√≥n correcta: {simbolo} {direccion} - TP alcanzado {precio_final:,.5f}")
                with open("correctas.txt", "a", encoding="utf-8") as file:
                    file.write(f"{timestamp} - {simbolo} - {direccion} (CORRECTA) - {precio_inicial:,.5f} -> {precio_final:,.5f}\n")
            else:
                error_magnitud = abs(precio_final - objetivo_tp) / abs(precio_inicial - objetivo_tp)
                recompensa = -2 if error_magnitud > 1.5 else -1 if error_magnitud > 1.1 else -0.5
                
                # ‚úÖ Asegurar que se guardan copias reales en memoria_errores
                memoria_errores.append((np.copy(X_train), np.copy(y_train), recompensa))
                logging.warning(f"‚ùå  Predicci√≥n incorrecta: {simbolo} NO {direccion}")
                with open("incorrectas.txt", "a", encoding="utf-8") as file:
                    file.write(f"{timestamp} - {simbolo} - {direccion} (INCORRECTA) - {precio_inicial:,.5f} -> {precio_final:,.5f}\n")

            # üî• Ajuste inmediato con refuerzo
            try:
                with tf.GradientTape() as tape:
                    predicciones = modelo(X_train, training=True)

                    # ‚úÖ Validaci√≥n antes de calcular la p√©rdida
                    if predicciones is None or y_train is None:
                        raise ValueError("üö® Error: 'predicciones' o 'y_train' es None.")

                    print(f"üîç Predicciones shape: {predicciones.shape}")  # Agregar depuraci√≥n

                    perdida = mse_loss(y_train, predicciones)
                    perdida = tf.reduce_mean(perdida) * (1 - recompensa)  # Modulaci√≥n con recompensa

                gradientes = tape.gradient(perdida, modelo.trainable_variables)
                modelo.optimizer.apply_gradients(zip(gradientes, modelo.trainable_variables))

            except Exception as e:
                logging.error(f"üö® Error durante el ajuste inmediato: {str(e)}")

            # üîÑ Correcci√≥n de errores recientes
            if len(memoria_errores) >= 10:
                X_err, y_err, recompensa_err = memoria_errores.popleft()
                with tf.GradientTape() as tape:
                    pred_err = modelo(X_err, training=True)
                    perdida_err = mse_loss(y_err, pred_err)
                    perdida_err = tf.reduce_mean(perdida_err) * (1 - recompensa_err)

                gradientes_err = tape.gradient(perdida_err, modelo.trainable_variables)
                modelo.optimizer.apply_gradients(zip(gradientes_err, modelo.trainable_variables))

            # üìâ Ajuste din√°mico de exploraci√≥n (Œµ-greedy)
            epsilon = max(0.05, epsilon * 0.99)

            total_predicciones += 1

            # üìä Evaluaci√≥n y guardado din√°mico
            if total_predicciones == 5000:
                logging.info(f"üìä Predicciones totales: {total_predicciones}, Aciertos: {aciertos_totales}")

                if aciertos_totales >= 4000:
                    nombre_modelo = f"modelo_{aciertos_totales}_de_5000.h5"
                    modelo.save(os.path.join(ruta_guardado, nombre_modelo))
                    logging.info(f"üíæ Modelo guardado: {nombre_modelo} con {aciertos_totales}/5000 predicciones correctas")

                elif aciertos_totales < 3500:
                    logging.warning("‚ö†Ô∏è Precisi√≥n menor al 70%. Se recomienda reajustar el modelo.")

    return aciertos_totales, total_predicciones


import logging
import time
import os
import pandas as pd
import MetaTrader5 as mt5
from sklearn.preprocessing import MinMaxScaler

def main():
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

    if not mt5.initialize():
        logging.error("‚ùå Error al inicializar MetaTrader 5.")
        return

    scaler = MinMaxScaler(feature_range=(0, 1))
    modelo = cargar_modelo()  # Aseg√∫rate de que esta funci√≥n est√© definida
    pares_divisas = ["BTCXAGm", "BTCXAUm", "BTCCNHm"]
    ruta_guardado = "C:/Users/pc/Desktop/PLAN CLASE HILDER/mi_entorno_1"

    if not os.path.exists(ruta_guardado):
        os.makedirs(ruta_guardado)

    logging.info("üìä Entrenando el modelo antes de predicciones en tiempo real...")
    datos_historicos = obtener_datos_mt5("BTCUSDm", mt5.TIMEFRAME_M1, 5000)

    if datos_historicos is not None and len(datos_historicos) > 50:
        X, y = preparar_datos(datos_historicos)
        split = int(len(X) * 0.8)
        modelo = entrenar_modelo(modelo, X[:split], y[:split], X[split:], y[split:])
        guardar_modelo(modelo)

    logging.info("‚úÖ Modelo cargado. Iniciando predicciones en tiempo real...")

    while True:
        logging.info("\n" + "="*50)
        logging.info("üîç Iniciando predicciones para todos los s√≠mbolos...")

        dfs = {}
        for simbolo in pares_divisas:
            rates = mt5.copy_rates_from_pos(simbolo, mt5.TIMEFRAME_M1, 0, 500)
            if rates is None or len(rates) < 50:
                logging.warning(f"‚ö†Ô∏è No hay suficientes datos recientes para {simbolo}.")
                continue

            df = pd.DataFrame(rates)[['close']]
            scaler.fit(df[['close']])
            df['close'] = scaler.transform(df[['close']])
            dfs[simbolo] = df

        if not dfs:
            logging.warning("‚ö†Ô∏è No se encontraron datos suficientes para predicciones.")
            time.sleep(5)
            continue

        try:
            predicciones = predecir_todos_los_simbolos(modelo, dfs, list(dfs.keys()), scaler)
            
            if predicciones is None:
                logging.error("‚ö†Ô∏è Error: predecir_todos_los_simbolos devolvi√≥ None. Revisar funci√≥n.")
                time.sleep(5)
                continue
            
            resultados_globales, resultados_futuros = predicciones
            evaluar_predicciones(resultados_globales, resultados_futuros, modelo, X, y, ruta_guardado)

        except Exception as e:
            logging.error(f"üö® Error durante la predicci√≥n: {e}", exc_info=True)

        print("\n" * 10 + "=" * 120)
        time.sleep(5)

if __name__ == "__main__":
    main()
